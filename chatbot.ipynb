{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "beOW7QtfTtHS",
        "outputId": "56b7c1ab-0c85-4dee-e831-545c89171d4f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/MyDrive/chat_bot\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "%cd /content/drive/MyDrive/chat_bot/\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import numpy as np\n",
        "import nltk\n",
        "import string\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('stopwords')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L0zEPE2aTwQf",
        "outputId": "e588d09c-812a-4536-a823-eb4a82ba36cf"
      },
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 120
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('intents.json') as file:\n",
        "    data = json.load(file)\n",
        "\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "def preprocess_text(text):\n",
        "    text = text.lower()\n",
        "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
        "    words = nltk.word_tokenize(text)\n",
        "    words = [lemmatizer.lemmatize(word) for word in words if word not in stop_words]\n",
        "    return words\n"
      ],
      "metadata": {
        "id": "1lc6OIuKTwSz"
      },
      "execution_count": 156,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N-30lctbteGe",
        "outputId": "d96d117c-0d1f-4bed-f8e2-c83766061c33"
      },
      "execution_count": 147,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'intents': [{'tag': 'greeting',\n",
              "   'patterns': ['Hi',\n",
              "    'How are you?',\n",
              "    'Is anyone there?',\n",
              "    'Hello',\n",
              "    'Good day',\n",
              "    \"What's up\",\n",
              "    'how are ya',\n",
              "    'heyy',\n",
              "    'whatsup',\n",
              "    '??? ??? ??'],\n",
              "   'responses': ['Hello!',\n",
              "    'Good to see you again!',\n",
              "    'Hi there, how can I help?'],\n",
              "   'context_set': ''},\n",
              "  {'tag': 'goodbye',\n",
              "   'patterns': ['cya',\n",
              "    'see you',\n",
              "    'bye bye',\n",
              "    'See you later',\n",
              "    'Goodbye',\n",
              "    'I am Leaving',\n",
              "    'Bye',\n",
              "    'Have a Good day',\n",
              "    'talk to you later',\n",
              "    'ttyl',\n",
              "    'i got to go',\n",
              "    'gtg'],\n",
              "   'responses': ['Sad to see you go :(',\n",
              "    'Talk to you later',\n",
              "    'Goodbye!',\n",
              "    'Come back soon'],\n",
              "   'context_set': ''},\n",
              "  {'tag': 'creator',\n",
              "   'patterns': ['what is the name of your developers',\n",
              "    'what is the name of your creators',\n",
              "    'what is the name of the developers',\n",
              "    'what is the name of the creators',\n",
              "    'who created you',\n",
              "    'your developers',\n",
              "    'your creators',\n",
              "    'who are your developers',\n",
              "    'developers',\n",
              "    'you are made by',\n",
              "    'you are made by whom',\n",
              "    'who created you',\n",
              "    'who create you',\n",
              "    'creators',\n",
              "    'who made you',\n",
              "    'who designed you'],\n",
              "   'responses': ['College students'],\n",
              "   'context_set': ''},\n",
              "  {'tag': 'name',\n",
              "   'patterns': ['name',\n",
              "    'your name',\n",
              "    'do you have a name',\n",
              "    'what are you called',\n",
              "    'what is your name',\n",
              "    'what should I call you',\n",
              "    'whats your name?',\n",
              "    'what are you',\n",
              "    'who are you',\n",
              "    'who is this',\n",
              "    'what am i chatting to',\n",
              "    'who am i taking to',\n",
              "    'what are you'],\n",
              "   'responses': ['You can call me Mind Reader.',\n",
              "    \"I'm Mind Reader\",\n",
              "    'I am a Chatbot.',\n",
              "    'I am your helper'],\n",
              "   'context_set': ''},\n",
              "  {'tag': 'hours',\n",
              "   'patterns': ['timing of college',\n",
              "    'what is college timing',\n",
              "    'working days',\n",
              "    'when are you guys open',\n",
              "    'what are your hours',\n",
              "    'hours of operation',\n",
              "    'when is the college open',\n",
              "    'college timing',\n",
              "    'what about college timing',\n",
              "    'is college open on saturday',\n",
              "    'tell something about college timing',\n",
              "    'what is the college  hours',\n",
              "    'when should i come to college',\n",
              "    'when should i attend college',\n",
              "    'what is my college time',\n",
              "    'college timing',\n",
              "    'timing college'],\n",
              "   'responses': ['College is open 8am-5pm Monday-Saturday!'],\n",
              "   'context_set': ''},\n",
              "  {'tag': 'number',\n",
              "   'patterns': ['more info',\n",
              "    'contact info',\n",
              "    'how to contact college',\n",
              "    'college telephone number',\n",
              "    'college number',\n",
              "    'What is your contact no',\n",
              "    'Contact number?',\n",
              "    'how to call you',\n",
              "    'College phone no?',\n",
              "    'how can i contact you',\n",
              "    'Can i get your phone number',\n",
              "    'how can i call you',\n",
              "    'phone number',\n",
              "    'phone no',\n",
              "    'call'],\n",
              "   'responses': ['You can contact at: NUMBER'],\n",
              "   'context_set': ''},\n",
              "  {'tag': 'course',\n",
              "   'patterns': ['list of courses',\n",
              "    'list of courses offered',\n",
              "    'list of courses offered in',\n",
              "    'what are the courses offered in your college?',\n",
              "    'courses?',\n",
              "    'courses offered',\n",
              "    'courses offered in (your univrsity(UNI) name)',\n",
              "    'courses you offer',\n",
              "    'branches?',\n",
              "    'courses available at UNI?',\n",
              "    'branches available at your college?',\n",
              "    'what are the courses in UNI?',\n",
              "    'what are branches in UNI?',\n",
              "    'what are courses in UNI?',\n",
              "    'branches available in UNI?',\n",
              "    'can you tell me the courses available in UNI?',\n",
              "    'can you tell me the branches available in UNI?',\n",
              "    'computer engineering?',\n",
              "    'computer',\n",
              "    'Computer engineering?',\n",
              "    'it',\n",
              "    'IT',\n",
              "    'Information Technology',\n",
              "    'AI/Ml',\n",
              "    'Mechanical engineering',\n",
              "    'Chemical engineering',\n",
              "    'Civil engineering'],\n",
              "   'responses': ['Our university offers Information Technology, computer Engineering, Mechanical engineering,Chemical engineering, Civil engineering and extc Engineering.'],\n",
              "   'context_set': ''},\n",
              "  {'tag': 'fees',\n",
              "   'patterns': ['information about fee',\n",
              "    'information on fee',\n",
              "    'tell me the fee',\n",
              "    'college fee',\n",
              "    'fee per semester',\n",
              "    'what is the fee of each semester',\n",
              "    'what is the fees of each year',\n",
              "    'what is fee',\n",
              "    'what is the fees',\n",
              "    'how much is the fees',\n",
              "    'fees for first year',\n",
              "    'fees',\n",
              "    'about the fees',\n",
              "    'tell me something about the fees',\n",
              "    'What is the fees of hostel',\n",
              "    'how much is the fees',\n",
              "    'hostel fees',\n",
              "    'fees for AC room',\n",
              "    'fees for non-AC room',\n",
              "    'fees for Ac room for girls',\n",
              "    'fees for non-Ac room for girls',\n",
              "    'fees for Ac room for boys',\n",
              "    'fees for non-Ac room for boys'],\n",
              "   'responses': ['For Fee detail visit <a target=\"_blank\" href=\"LINK\"> here</a>'],\n",
              "   'context_set': ''},\n",
              "  {'tag': 'location',\n",
              "   'patterns': ['where is the college located',\n",
              "    'college is located at',\n",
              "    'where is college',\n",
              "    'where is college located',\n",
              "    'address of college',\n",
              "    'how to reach college',\n",
              "    'college location',\n",
              "    'college address',\n",
              "    'wheres the college',\n",
              "    'how can I reach college',\n",
              "    'whats is the college address',\n",
              "    'what is the address of college',\n",
              "    'address',\n",
              "    'location'],\n",
              "   'responses': ['<a target=\"_blank\" href=\"ADD YOU GOOGLE MAP LINK HERE\"> here</a>'],\n",
              "   'context_set': ''},\n",
              "  {'tag': 'hostel',\n",
              "   'patterns': ['hostel facility',\n",
              "    'hostel servive',\n",
              "    'hostel location',\n",
              "    'hostel address',\n",
              "    'hostel facilities',\n",
              "    'hostel fees',\n",
              "    'Does college provide hostel',\n",
              "    'Is there any hostel',\n",
              "    'Where is hostel',\n",
              "    'do you have hostel',\n",
              "    'do you guys have hostel',\n",
              "    'hostel',\n",
              "    'hostel capacity',\n",
              "    'what is the hostel fee',\n",
              "    'how to get in hostel',\n",
              "    'what is the hostel address',\n",
              "    'how far is hostel from college',\n",
              "    'hostel college distance',\n",
              "    'where is the hostel',\n",
              "    'how big is the hostel',\n",
              "    'distance between college and hostel',\n",
              "    'distance between hostel and college'],\n",
              "   'responses': ['For hostel detail visit <a target=\"_blank\" href=\"ADD YOUR HOSTEL DETAIL PDF LINK OR ANY INFORMATION LINK OR ADD YOU OWN ANSWERS\"> here</a>'],\n",
              "   'context_set': ''},\n",
              "  {'tag': 'event',\n",
              "   'patterns': ['events organised',\n",
              "    'list of events',\n",
              "    'list of events organised in college',\n",
              "    'list of events conducted in college',\n",
              "    'What events are conducted in college',\n",
              "    'Are there any event held at college',\n",
              "    'Events?',\n",
              "    'functions',\n",
              "    'what are the events',\n",
              "    'tell me about events',\n",
              "    'what about events'],\n",
              "   'responses': ['For event detail visit <a target=\"_blank\" href=\"ADD YOUR FUNCTIONS LINK OR YOUR OWN RESPONSE\"> here</a>'],\n",
              "   'context_set': ''},\n",
              "  {'tag': 'document',\n",
              "   'patterns': ['document to bring',\n",
              "    'documents needed for admision',\n",
              "    'documents needed at the time of admission',\n",
              "    'documents needed during admission',\n",
              "    'documents required for admision',\n",
              "    'documents required at the time of admission',\n",
              "    'documents required during admission',\n",
              "    'What document are required for admission',\n",
              "    'Which document to bring for admission',\n",
              "    'documents',\n",
              "    'what documents do i need',\n",
              "    'what documents do I need for admission',\n",
              "    'documents needed'],\n",
              "   'responses': ['To know more about document required visit <a target=\"_blank\" href=\"ADD LINK OF ADMISSION GUIDANCE DOCUMENT FROM YOUR UNIVERSITY WEBSITE\"> here</a>'],\n",
              "   'context_set': ''},\n",
              "  {'tag': 'floors',\n",
              "   'patterns': ['size of campus',\n",
              "    'building size',\n",
              "    'How many floors does college have',\n",
              "    'floors in college',\n",
              "    'floors in college',\n",
              "    \"how tall is UNI's College of Engineering college building\",\n",
              "    'floors'],\n",
              "   'responses': ['My College has total 2 floors '],\n",
              "   'context_set': ''},\n",
              "  {'tag': 'syllabus',\n",
              "   'patterns': ['Syllabus for IT',\n",
              "    'what is the Information Technology syllabus',\n",
              "    'syllabus',\n",
              "    'timetable',\n",
              "    'what is IT syllabus',\n",
              "    'syllabus',\n",
              "    'What is next lecture'],\n",
              "   'responses': ['Timetable provide direct to the students OR To know about syllabus visit <a target=\"_blank\" href=\"TIMETABLE LINK\"> here</a>'],\n",
              "   'context_set': ''},\n",
              "  {'tag': 'library',\n",
              "   'patterns': ['is there any library',\n",
              "    'library facility',\n",
              "    'library facilities',\n",
              "    'do you have library',\n",
              "    'does the college have library facility',\n",
              "    'college library',\n",
              "    'where can i get books',\n",
              "    'book facility',\n",
              "    'Where is library',\n",
              "    'Library',\n",
              "    'Library information',\n",
              "    'Library books information',\n",
              "    'Tell me about library',\n",
              "    'how many libraries'],\n",
              "   'responses': ['There is one huge and spacious library.timings are 8am to 6pm and for more visit <a target=\"blank\" href=\"ADD LIBRARY DETAIL LINK\">here</a>'],\n",
              "   'context_set': ''},\n",
              "  {'tag': 'infrastructure',\n",
              "   'patterns': ['how is college infrastructure',\n",
              "    'infrastructure',\n",
              "    'college infrastructure'],\n",
              "   'responses': ['Our University has Excellent Infrastructure. Campus is clean. Good IT Labs With Good Speed of Internet connection'],\n",
              "   'context_set': ''},\n",
              "  {'tag': 'canteen',\n",
              "   'patterns': ['food facilities',\n",
              "    'canteen facilities',\n",
              "    'canteen facility',\n",
              "    'is there any canteen',\n",
              "    'Is there a cafetaria in college',\n",
              "    'Does college have canteen',\n",
              "    'Where is canteen',\n",
              "    'where is cafetaria',\n",
              "    'canteen',\n",
              "    'Food',\n",
              "    'Cafetaria'],\n",
              "   'responses': ['Our university has canteen with variety of food available'],\n",
              "   'context_set': ''},\n",
              "  {'tag': 'menu',\n",
              "   'patterns': ['food menu',\n",
              "    'food in canteen',\n",
              "    'Whats there on menu',\n",
              "    'what is available in college canteen',\n",
              "    'what foods can we get in college canteen',\n",
              "    'food variety',\n",
              "    'What is there to eat?'],\n",
              "   'responses': ['we serve Franky, Locho, Alu-puri, Kachori, Khavsa, Thaali and many more on menu'],\n",
              "   'context_set': ''},\n",
              "  {'tag': 'placement',\n",
              "   'patterns': ['What is college placement',\n",
              "    'Which companies visit in college',\n",
              "    'What is average package',\n",
              "    'companies visit',\n",
              "    'package',\n",
              "    'About placement',\n",
              "    'placement',\n",
              "    'recruitment',\n",
              "    'companies'],\n",
              "   'responses': ['To know about placement visit <a target=\"_blank\" href=\"PLACEMENT INFORMATION LINK FROM YOUR UNIVERSITY WEBSITE IF THEY HAVE\">here</a>'],\n",
              "   'context_set': ''},\n",
              "  {'tag': 'ithod',\n",
              "   'patterns': ['Who is HOD', 'Where is HOD', 'it hod', 'name of it hod'],\n",
              "   'responses': ['All engineering departments have only one hod XYZ who available on (Place name)'],\n",
              "   'context_set': ''},\n",
              "  {'tag': 'computerhod',\n",
              "   'patterns': ['Who is computer HOD',\n",
              "    'Where is computer HOD',\n",
              "    'computer hod',\n",
              "    'name of computer hod'],\n",
              "   'responses': ['All engineering departments have only one hod XYZ who available on (PLACE NAME)'],\n",
              "   'context_set': ''},\n",
              "  {'tag': 'extchod',\n",
              "   'patterns': ['Who is extc HOD',\n",
              "    'Where is  extc HOD',\n",
              "    'extc hod',\n",
              "    'name of extc hod'],\n",
              "   'responses': ['Different school wise hod are different.So be more clear with your school or department'],\n",
              "   'context_set': ''},\n",
              "  {'tag': 'principal',\n",
              "   'patterns': ['what is the name of principal',\n",
              "    'whatv is the principal name',\n",
              "    'principal name',\n",
              "    'Who is college principal',\n",
              "    \"Where is principal's office\",\n",
              "    'principal',\n",
              "    'name of principal'],\n",
              "   'responses': ['XYZ is college principal and if you need any help then call your branch hod first.That is more appropriate'],\n",
              "   'context_set': ''},\n",
              "  {'tag': 'sem',\n",
              "   'patterns': ['exam dates',\n",
              "    'exam schedule',\n",
              "    'When is semester exam',\n",
              "    'Semester exam timetable',\n",
              "    'sem',\n",
              "    'semester',\n",
              "    'exam',\n",
              "    'when is exam',\n",
              "    'exam timetable',\n",
              "    'exam dates',\n",
              "    'when is semester'],\n",
              "   'responses': ['Here is the Academic Calendar  <a target=\"_blank\" href=\"YOUR ACADEMIC CALENDER\">website</a>'],\n",
              "   'context_set': ''},\n",
              "  {'tag': 'admission',\n",
              "   'patterns': ['what is the process of admission',\n",
              "    'what is the admission process',\n",
              "    'How to take admission in your college',\n",
              "    'What is the process for admission',\n",
              "    'admission',\n",
              "    'admission process'],\n",
              "   'responses': ['Application can also be submitted online through the Unversity\\'s  <a target=\"_blank\" href=\"LINK OF ADMISSION DOCUMENT\">website</a>'],\n",
              "   'context_set': ''},\n",
              "  {'tag': 'scholarship',\n",
              "   'patterns': ['scholarship',\n",
              "    'Is scholarship available',\n",
              "    'scholarship engineering',\n",
              "    'scholarship it',\n",
              "    'scholarship ce',\n",
              "    'scholarship mechanical',\n",
              "    'scholarship civil',\n",
              "    'scholarship chemical',\n",
              "    'scholarship for AI/ML',\n",
              "    'available scholarships',\n",
              "    'scholarship for computer engineering',\n",
              "    'scholarship for IT engineering',\n",
              "    'scholarship for mechanical engineering',\n",
              "    'scholarship for civil engineering',\n",
              "    'scholarship for chemical engineering',\n",
              "    'list of scholarship',\n",
              "    'comps scholarship',\n",
              "    'IT scholarship',\n",
              "    'mechanical scholarship',\n",
              "    'civil scholarship',\n",
              "    'chemical scholarship',\n",
              "    'automobile scholarship',\n",
              "    'first year scholarship',\n",
              "    'second year scholarship',\n",
              "    'third year scholarship',\n",
              "    'fourth year scholarship'],\n",
              "   'responses': ['Many government scholarships are supported by our university. For details and updates visit <a target=\"_blank\" href=\"(SCHOLARSHIP DETAILS LINK)\">here</a>'],\n",
              "   'context_set': ''},\n",
              "  {'tag': 'facilities',\n",
              "   'patterns': ['What facilities college provide',\n",
              "    'College facility',\n",
              "    'What are college facilities',\n",
              "    'facilities',\n",
              "    'facilities provided'],\n",
              "   'responses': [\"Our university's Engineering department provides fully AC Lab with internet connection, smart classroom, Auditorium, library,canteen\"],\n",
              "   'context_set': ''},\n",
              "  {'tag': 'college intake',\n",
              "   'patterns': ['max number of students',\n",
              "    'number of seats per branch',\n",
              "    'number of seats in each branch',\n",
              "    'maximum number of seats',\n",
              "    'maximum students intake',\n",
              "    'What is college intake',\n",
              "    'how many stundent are taken in each branch',\n",
              "    'seat allotment',\n",
              "    'seats'],\n",
              "   'responses': ['For IT, Computer and extc 60 per branch and seat may be differ for different department.'],\n",
              "   'context_set': ''},\n",
              "  {'tag': 'uniform',\n",
              "   'patterns': ['college dress code',\n",
              "    'college dresscode',\n",
              "    'what is the uniform',\n",
              "    'can we wear casuals',\n",
              "    'Does college have an uniform',\n",
              "    'Is there any uniform',\n",
              "    'uniform',\n",
              "    'what about uniform',\n",
              "    'do we have to wear uniform'],\n",
              "   'responses': ['ENTER YOUR OWN UNIVERSITY UNIFORM CIRCULER'],\n",
              "   'context_set': ''},\n",
              "  {'tag': 'committee',\n",
              "   'patterns': ['what are the different committe in college',\n",
              "    'different committee in college',\n",
              "    'Are there any committee in college',\n",
              "    'Give me committee details',\n",
              "    'committee',\n",
              "    'how many committee are there in college'],\n",
              "   'responses': ['For the various committe in college contact this number: ADD NUMBER'],\n",
              "   'context_set': ''},\n",
              "  {'tag': 'random',\n",
              "   'patterns': ['I love you', 'Will you marry me', 'Do you love me'],\n",
              "   'responses': ['I am not program for this, please ask appropriate query'],\n",
              "   'context_set': ''},\n",
              "  {'tag': 'swear',\n",
              "   'patterns': ['fuck',\n",
              "    'bitch',\n",
              "    'shut up',\n",
              "    'hell',\n",
              "    'stupid',\n",
              "    'idiot',\n",
              "    'dumb ass',\n",
              "    'asshole',\n",
              "    'fucker'],\n",
              "   'responses': ['please use appropriate language',\n",
              "    'Maintaining decency would be appreciated'],\n",
              "   'context_set': ''},\n",
              "  {'tag': 'vacation',\n",
              "   'patterns': ['holidays',\n",
              "    'when will semester starts',\n",
              "    'when will semester end',\n",
              "    'when is the holidays',\n",
              "    'list of holidays',\n",
              "    'Holiday in these year',\n",
              "    'holiday list',\n",
              "    'about vacations',\n",
              "    'about holidays',\n",
              "    'When is vacation',\n",
              "    'When is holidays',\n",
              "    'how long will be the vacation'],\n",
              "   'responses': ['Academic calender is given to you by your class-soordinators after you join your respective classes'],\n",
              "   'context_set': ''},\n",
              "  {'tag': 'sports',\n",
              "   'patterns': ['sports and games',\n",
              "    'give sports details',\n",
              "    'sports infrastructure',\n",
              "    'sports facilities',\n",
              "    'information about sports',\n",
              "    'Sports activities',\n",
              "    'please provide sports and games information'],\n",
              "   'responses': ['Our university encourages all-round development of students and hence provides sports facilities in the campus. For more details visit<a target=\"_blank\" href=/\"(LINK IF HAVE)\">here</a>'],\n",
              "   'context_set': ''},\n",
              "  {'tag': 'salutaion',\n",
              "   'patterns': ['okk',\n",
              "    'okie',\n",
              "    'nice work',\n",
              "    'well done',\n",
              "    'good job',\n",
              "    'thanks for the help',\n",
              "    'Thank You',\n",
              "    'its ok',\n",
              "    'Thanks',\n",
              "    'Good work',\n",
              "    'k',\n",
              "    'ok',\n",
              "    'okay'],\n",
              "   'responses': ['I am glad I helped you',\n",
              "    'welcome, anything else i can assist you with?'],\n",
              "   'context_set': ''},\n",
              "  {'tag': 'task',\n",
              "   'patterns': ['what can you do',\n",
              "    'what are the thing you can do',\n",
              "    'things you can do',\n",
              "    'what can u do for me',\n",
              "    'how u can help me',\n",
              "    'why i should use you'],\n",
              "   'responses': ['I can answer to low-intermediate questions regarding college',\n",
              "    'You can ask me questions regarding college, and i will try to answer them'],\n",
              "   'context_set': ''},\n",
              "  {'tag': 'ragging',\n",
              "   'patterns': ['ragging',\n",
              "    'is ragging practice active in college',\n",
              "    'does college have any antiragging facility',\n",
              "    'is there any ragging cases',\n",
              "    'is ragging done here',\n",
              "    'ragging against',\n",
              "    'antiragging facility',\n",
              "    'ragging juniors',\n",
              "    'ragging history',\n",
              "    'ragging incidents'],\n",
              "   'responses': ['We are Proud to tell you that our college provides ragging free environment, and we have strict rules against ragging'],\n",
              "   'context_set': ''},\n",
              "  {'tag': 'hod',\n",
              "   'patterns': ['hod', 'hod name', 'who is the hod'],\n",
              "   'responses': ['HODs differ for each branch, please be more specific like: (HOD it)'],\n",
              "   'context_set': ''}]}"
            ]
          },
          "metadata": {},
          "execution_count": 147
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "training_sentences = []\n",
        "training_labels = []\n",
        "labels = []\n",
        "responses = []\n",
        "\n",
        "for intent in data['intents']:\n",
        "    for pattern in intent['patterns']:\n",
        "        processed_pattern = preprocess_text(pattern)\n",
        "        training_sentences.append(' '.join(processed_pattern))\n",
        "        training_labels.append(intent['tag'])\n",
        "    responses.append(intent['responses'])\n",
        "\n",
        "    if intent['tag'] not in labels:\n",
        "        labels.append(intent['tag'])\n"
      ],
      "metadata": {
        "id": "WMlur7srTwUp"
      },
      "execution_count": 157,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label_encoder = LabelEncoder()\n",
        "training_labels = label_encoder.fit_transform(training_labels)\n"
      ],
      "metadata": {
        "id": "MaSzcY4ITwWm"
      },
      "execution_count": 158,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = 2000\n",
        "max_len = 20\n",
        "\n",
        "tokenizer = Tokenizer(num_words=vocab_size, oov_token=\"<OOV>\")\n",
        "tokenizer.fit_on_texts(training_sentences)\n",
        "sequences = tokenizer.texts_to_sequences(training_sentences)\n",
        "padded_sequences = pad_sequences(sequences, maxlen=max_len, truncating='post')\n"
      ],
      "metadata": {
        "id": "xLUm_ZbLTwYs"
      },
      "execution_count": 159,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Embedding, GlobalAveragePooling1D, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n"
      ],
      "metadata": {
        "id": "L39gy3aUTwhz"
      },
      "execution_count": 160,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(vocab_size, 16, input_length=max_len))\n",
        "model.add(GlobalAveragePooling1D())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(len(labels), activation='softmax'))\n",
        "\n",
        "model.compile(loss='sparse_categorical_crossentropy',\n",
        "              optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(padded_sequences, np.array(training_labels),\n",
        "                    epochs=300, verbose=1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OjgKrsYzTwkQ",
        "outputId": "adcd845a-4a98-46fa-a76f-5e719b351267"
      },
      "execution_count": 161,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/300\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.0155 - loss: 3.6376\n",
            "Epoch 2/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0632 - loss: 3.6294\n",
            "Epoch 3/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0770 - loss: 3.6210\n",
            "Epoch 4/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0581 - loss: 3.6062\n",
            "Epoch 5/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0638 - loss: 3.5843\n",
            "Epoch 6/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0917 - loss: 3.5381\n",
            "Epoch 7/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0560 - loss: 3.5438\n",
            "Epoch 8/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0675 - loss: 3.5207\n",
            "Epoch 9/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0648 - loss: 3.4942\n",
            "Epoch 10/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0913 - loss: 3.5079\n",
            "Epoch 11/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0422 - loss: 3.5128\n",
            "Epoch 12/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0831 - loss: 3.4894\n",
            "Epoch 13/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0715 - loss: 3.4780\n",
            "Epoch 14/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0543 - loss: 3.4638\n",
            "Epoch 15/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0792 - loss: 3.4854\n",
            "Epoch 16/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0692 - loss: 3.4974\n",
            "Epoch 17/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0802 - loss: 3.4749\n",
            "Epoch 18/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0996 - loss: 3.4681\n",
            "Epoch 19/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0665 - loss: 3.4955\n",
            "Epoch 20/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0690 - loss: 3.4504\n",
            "Epoch 21/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0508 - loss: 3.4509\n",
            "Epoch 22/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0621 - loss: 3.4445\n",
            "Epoch 23/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0576 - loss: 3.4408\n",
            "Epoch 24/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0332 - loss: 3.4324\n",
            "Epoch 25/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0823 - loss: 3.4049 \n",
            "Epoch 26/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0523 - loss: 3.3945 \n",
            "Epoch 27/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0650 - loss: 3.3366 \n",
            "Epoch 28/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0868 - loss: 3.2977\n",
            "Epoch 29/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1000 - loss: 3.2644\n",
            "Epoch 30/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0561 - loss: 3.2217\n",
            "Epoch 31/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0677 - loss: 3.1726 \n",
            "Epoch 32/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0785 - loss: 3.1564\n",
            "Epoch 33/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0912 - loss: 3.1604 \n",
            "Epoch 34/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0793 - loss: 3.1128 \n",
            "Epoch 35/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0716 - loss: 3.1234 \n",
            "Epoch 36/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0988 - loss: 3.1006\n",
            "Epoch 37/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0803 - loss: 3.0400\n",
            "Epoch 38/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0614 - loss: 3.0543\n",
            "Epoch 39/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0614 - loss: 3.0311\n",
            "Epoch 40/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0950 - loss: 3.0121 \n",
            "Epoch 41/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.1091 - loss: 2.9950 \n",
            "Epoch 42/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1199 - loss: 2.9827\n",
            "Epoch 43/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.1223 - loss: 2.9763\n",
            "Epoch 44/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.1030 - loss: 2.9253\n",
            "Epoch 45/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.1058 - loss: 2.9319\n",
            "Epoch 46/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.1261 - loss: 2.9250\n",
            "Epoch 47/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1542 - loss: 2.8977\n",
            "Epoch 48/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.1075 - loss: 2.9023\n",
            "Epoch 49/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.1367 - loss: 2.8654\n",
            "Epoch 50/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.1567 - loss: 2.7911\n",
            "Epoch 51/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.1412 - loss: 2.8024\n",
            "Epoch 52/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.1411 - loss: 2.7887\n",
            "Epoch 53/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.1734 - loss: 2.7318\n",
            "Epoch 54/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1991 - loss: 2.7196\n",
            "Epoch 55/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1867 - loss: 2.6969\n",
            "Epoch 56/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.1869 - loss: 2.6911 \n",
            "Epoch 57/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.1838 - loss: 2.6952 \n",
            "Epoch 58/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2119 - loss: 2.5901 \n",
            "Epoch 59/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.2130 - loss: 2.5952\n",
            "Epoch 60/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.2342 - loss: 2.5827\n",
            "Epoch 61/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.2309 - loss: 2.5656\n",
            "Epoch 62/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.2459 - loss: 2.5173\n",
            "Epoch 63/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.2246 - loss: 2.5201\n",
            "Epoch 64/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.2557 - loss: 2.4664\n",
            "Epoch 65/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2341 - loss: 2.4564 \n",
            "Epoch 66/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3059 - loss: 2.3745\n",
            "Epoch 67/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.2675 - loss: 2.3853\n",
            "Epoch 68/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2715 - loss: 2.3295  \n",
            "Epoch 69/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2359 - loss: 2.4025  \n",
            "Epoch 70/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2597 - loss: 2.3498  \n",
            "Epoch 71/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3063 - loss: 2.3323 \n",
            "Epoch 72/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2511 - loss: 2.3241  \n",
            "Epoch 73/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2775 - loss: 2.2450 \n",
            "Epoch 74/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3332 - loss: 2.2172 \n",
            "Epoch 75/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2926 - loss: 2.2511 \n",
            "Epoch 76/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3215 - loss: 2.2471 \n",
            "Epoch 77/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3010 - loss: 2.2439 \n",
            "Epoch 78/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3026 - loss: 2.2292 \n",
            "Epoch 79/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3297 - loss: 2.2022  \n",
            "Epoch 80/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3259 - loss: 2.2376 \n",
            "Epoch 81/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3140 - loss: 2.2255 \n",
            "Epoch 82/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3158 - loss: 2.1954 \n",
            "Epoch 83/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2925 - loss: 2.2794 \n",
            "Epoch 84/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3271 - loss: 2.2990 \n",
            "Epoch 85/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3362 - loss: 2.2474 \n",
            "Epoch 86/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3573 - loss: 2.1224\n",
            "Epoch 87/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3689 - loss: 2.0681 \n",
            "Epoch 88/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3939 - loss: 2.0488 \n",
            "Epoch 89/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4172 - loss: 1.9466 \n",
            "Epoch 90/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3422 - loss: 2.0038  \n",
            "Epoch 91/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3940 - loss: 2.0067  \n",
            "Epoch 92/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3894 - loss: 1.9875 \n",
            "Epoch 93/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3973 - loss: 1.9305 \n",
            "Epoch 94/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4210 - loss: 1.8901 \n",
            "Epoch 95/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4140 - loss: 1.8851  \n",
            "Epoch 96/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4382 - loss: 1.8181 \n",
            "Epoch 97/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4333 - loss: 1.8437 \n",
            "Epoch 98/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4296 - loss: 1.8246 \n",
            "Epoch 99/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4242 - loss: 1.8534 \n",
            "Epoch 100/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4211 - loss: 1.8370 \n",
            "Epoch 101/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4294 - loss: 1.7844 \n",
            "Epoch 102/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4688 - loss: 1.7663  \n",
            "Epoch 103/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4317 - loss: 1.7843 \n",
            "Epoch 104/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4621 - loss: 1.7455\n",
            "Epoch 105/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4496 - loss: 1.7586 \n",
            "Epoch 106/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4246 - loss: 1.7936 \n",
            "Epoch 107/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4505 - loss: 1.7037 \n",
            "Epoch 108/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4582 - loss: 1.7085  \n",
            "Epoch 109/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4608 - loss: 1.6259 \n",
            "Epoch 110/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4740 - loss: 1.5928 \n",
            "Epoch 111/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4737 - loss: 1.6300  \n",
            "Epoch 112/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5155 - loss: 1.5650 \n",
            "Epoch 113/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5280 - loss: 1.5372 \n",
            "Epoch 114/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4776 - loss: 1.6453 \n",
            "Epoch 115/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4451 - loss: 1.6240  \n",
            "Epoch 116/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4721 - loss: 1.6119 \n",
            "Epoch 117/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4466 - loss: 1.5965 \n",
            "Epoch 118/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4852 - loss: 1.5761 \n",
            "Epoch 119/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4665 - loss: 1.5793 \n",
            "Epoch 120/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5100 - loss: 1.4717 \n",
            "Epoch 121/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5200 - loss: 1.5173 \n",
            "Epoch 122/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5175 - loss: 1.4886 \n",
            "Epoch 123/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5411 - loss: 1.4479  \n",
            "Epoch 124/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4923 - loss: 1.5149 \n",
            "Epoch 125/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4947 - loss: 1.5034  \n",
            "Epoch 126/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4964 - loss: 1.5401 \n",
            "Epoch 127/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5096 - loss: 1.5245 \n",
            "Epoch 128/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5561 - loss: 1.3823 \n",
            "Epoch 129/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5430 - loss: 1.3591  \n",
            "Epoch 130/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5432 - loss: 1.3862  \n",
            "Epoch 131/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5141 - loss: 1.4820 \n",
            "Epoch 132/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5498 - loss: 1.4211\n",
            "Epoch 133/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5210 - loss: 1.4505 \n",
            "Epoch 134/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5294 - loss: 1.3339 \n",
            "Epoch 135/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5651 - loss: 1.3737 \n",
            "Epoch 136/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5860 - loss: 1.3725 \n",
            "Epoch 137/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5601 - loss: 1.3918 \n",
            "Epoch 138/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5668 - loss: 1.3036 \n",
            "Epoch 139/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6362 - loss: 1.2066 \n",
            "Epoch 140/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5594 - loss: 1.3234 \n",
            "Epoch 141/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6211 - loss: 1.2268 \n",
            "Epoch 142/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5931 - loss: 1.2704  \n",
            "Epoch 143/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6279 - loss: 1.1902 \n",
            "Epoch 144/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5902 - loss: 1.2599  \n",
            "Epoch 145/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5650 - loss: 1.2661 \n",
            "Epoch 146/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6384 - loss: 1.1027 \n",
            "Epoch 147/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6148 - loss: 1.2138 \n",
            "Epoch 148/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5867 - loss: 1.2029 \n",
            "Epoch 149/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5214 - loss: 1.2708 \n",
            "Epoch 150/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5986 - loss: 1.1773 \n",
            "Epoch 151/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6478 - loss: 1.1218 \n",
            "Epoch 152/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5792 - loss: 1.2307 \n",
            "Epoch 153/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5894 - loss: 1.2475 \n",
            "Epoch 154/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5894 - loss: 1.1973 \n",
            "Epoch 155/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5812 - loss: 1.2487 \n",
            "Epoch 156/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6543 - loss: 1.0884 \n",
            "Epoch 157/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6379 - loss: 1.1437 \n",
            "Epoch 158/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6169 - loss: 1.1481 \n",
            "Epoch 159/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6311 - loss: 1.1298  \n",
            "Epoch 160/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6623 - loss: 1.1132  \n",
            "Epoch 161/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6190 - loss: 1.1546 \n",
            "Epoch 162/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6560 - loss: 1.0489  \n",
            "Epoch 163/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6393 - loss: 1.0830 \n",
            "Epoch 164/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6627 - loss: 1.0238\n",
            "Epoch 165/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6309 - loss: 1.0171\n",
            "Epoch 166/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6644 - loss: 1.0072\n",
            "Epoch 167/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6792 - loss: 0.9739\n",
            "Epoch 168/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6558 - loss: 1.0800\n",
            "Epoch 169/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6380 - loss: 1.0862\n",
            "Epoch 170/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6759 - loss: 0.9763\n",
            "Epoch 171/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6423 - loss: 0.9810\n",
            "Epoch 172/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6675 - loss: 1.0282 \n",
            "Epoch 173/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6919 - loss: 0.9395\n",
            "Epoch 174/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6682 - loss: 1.0340 \n",
            "Epoch 175/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6695 - loss: 1.0340 \n",
            "Epoch 176/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6685 - loss: 0.9762\n",
            "Epoch 177/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7125 - loss: 0.9503\n",
            "Epoch 178/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6744 - loss: 0.9783\n",
            "Epoch 179/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6965 - loss: 0.8815\n",
            "Epoch 180/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6981 - loss: 0.9320\n",
            "Epoch 181/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7158 - loss: 0.9247\n",
            "Epoch 182/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6900 - loss: 0.9404 \n",
            "Epoch 183/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7438 - loss: 0.8226\n",
            "Epoch 184/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6992 - loss: 0.9612\n",
            "Epoch 185/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6880 - loss: 0.9482\n",
            "Epoch 186/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7525 - loss: 0.7993\n",
            "Epoch 187/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7275 - loss: 0.8456 \n",
            "Epoch 188/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7402 - loss: 0.7994 \n",
            "Epoch 189/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7204 - loss: 0.8559\n",
            "Epoch 190/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7004 - loss: 0.8737\n",
            "Epoch 191/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6699 - loss: 0.8684\n",
            "Epoch 192/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7580 - loss: 0.7904\n",
            "Epoch 193/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7268 - loss: 0.8097\n",
            "Epoch 194/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7134 - loss: 0.8633\n",
            "Epoch 195/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7094 - loss: 0.8420\n",
            "Epoch 196/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7647 - loss: 0.8228\n",
            "Epoch 197/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7469 - loss: 0.7330\n",
            "Epoch 198/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7329 - loss: 0.8426\n",
            "Epoch 199/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7048 - loss: 0.8564\n",
            "Epoch 200/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7235 - loss: 0.8638\n",
            "Epoch 201/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7069 - loss: 0.7791\n",
            "Epoch 202/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7557 - loss: 0.7588\n",
            "Epoch 203/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7534 - loss: 0.7625\n",
            "Epoch 204/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7226 - loss: 0.8011\n",
            "Epoch 205/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7998 - loss: 0.7649\n",
            "Epoch 206/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7471 - loss: 0.7694\n",
            "Epoch 207/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7673 - loss: 0.7432\n",
            "Epoch 208/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7354 - loss: 0.8114\n",
            "Epoch 209/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7244 - loss: 0.8253\n",
            "Epoch 210/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7541 - loss: 0.7317\n",
            "Epoch 211/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7241 - loss: 0.7998\n",
            "Epoch 212/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7721 - loss: 0.7198\n",
            "Epoch 213/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7575 - loss: 0.7661\n",
            "Epoch 214/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7375 - loss: 0.8082\n",
            "Epoch 215/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7627 - loss: 0.7633\n",
            "Epoch 216/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7485 - loss: 0.7185\n",
            "Epoch 217/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7563 - loss: 0.6935\n",
            "Epoch 218/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7946 - loss: 0.6608\n",
            "Epoch 219/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7953 - loss: 0.6714\n",
            "Epoch 220/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7887 - loss: 0.6549 \n",
            "Epoch 221/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7665 - loss: 0.6906 \n",
            "Epoch 222/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7608 - loss: 0.6848 \n",
            "Epoch 223/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7444 - loss: 0.7295\n",
            "Epoch 224/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7775 - loss: 0.6906 \n",
            "Epoch 225/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7843 - loss: 0.7214\n",
            "Epoch 226/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7600 - loss: 0.6923\n",
            "Epoch 227/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7781 - loss: 0.6981\n",
            "Epoch 228/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8193 - loss: 0.6331\n",
            "Epoch 229/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8231 - loss: 0.5885\n",
            "Epoch 230/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7685 - loss: 0.6155\n",
            "Epoch 231/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7700 - loss: 0.7289\n",
            "Epoch 232/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7618 - loss: 0.7190\n",
            "Epoch 233/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7581 - loss: 0.7146\n",
            "Epoch 234/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7379 - loss: 0.7325\n",
            "Epoch 235/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7991 - loss: 0.7309\n",
            "Epoch 236/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7952 - loss: 0.6480\n",
            "Epoch 237/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7791 - loss: 0.6406\n",
            "Epoch 238/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8012 - loss: 0.6538\n",
            "Epoch 239/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7809 - loss: 0.6235\n",
            "Epoch 240/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8039 - loss: 0.6418\n",
            "Epoch 241/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7444 - loss: 0.6957\n",
            "Epoch 242/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8121 - loss: 0.6142 \n",
            "Epoch 243/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7898 - loss: 0.6638\n",
            "Epoch 244/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7999 - loss: 0.6242\n",
            "Epoch 245/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8181 - loss: 0.6328 \n",
            "Epoch 246/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7841 - loss: 0.5828\n",
            "Epoch 247/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7653 - loss: 0.6945\n",
            "Epoch 248/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8060 - loss: 0.5737\n",
            "Epoch 249/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7884 - loss: 0.6353\n",
            "Epoch 250/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7780 - loss: 0.6170\n",
            "Epoch 251/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8086 - loss: 0.6312\n",
            "Epoch 252/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7838 - loss: 0.5992\n",
            "Epoch 253/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8168 - loss: 0.5704 \n",
            "Epoch 254/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8279 - loss: 0.5588 \n",
            "Epoch 255/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7920 - loss: 0.5818\n",
            "Epoch 256/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8112 - loss: 0.6059\n",
            "Epoch 257/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8370 - loss: 0.5280\n",
            "Epoch 258/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8450 - loss: 0.5366\n",
            "Epoch 259/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8028 - loss: 0.5946\n",
            "Epoch 260/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8124 - loss: 0.5532\n",
            "Epoch 261/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8015 - loss: 0.6157\n",
            "Epoch 262/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8104 - loss: 0.5686\n",
            "Epoch 263/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8028 - loss: 0.6006\n",
            "Epoch 264/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8297 - loss: 0.6410\n",
            "Epoch 265/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8100 - loss: 0.5608\n",
            "Epoch 266/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7934 - loss: 0.5857\n",
            "Epoch 267/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8212 - loss: 0.5673\n",
            "Epoch 268/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8207 - loss: 0.5738\n",
            "Epoch 269/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8163 - loss: 0.5146 \n",
            "Epoch 270/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8081 - loss: 0.5457\n",
            "Epoch 271/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8325 - loss: 0.5854\n",
            "Epoch 272/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8253 - loss: 0.5240\n",
            "Epoch 273/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8249 - loss: 0.5302\n",
            "Epoch 274/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8260 - loss: 0.5637\n",
            "Epoch 275/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8241 - loss: 0.4889\n",
            "Epoch 276/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8256 - loss: 0.5019\n",
            "Epoch 277/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8430 - loss: 0.5583\n",
            "Epoch 278/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7939 - loss: 0.5792 \n",
            "Epoch 279/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8549 - loss: 0.4849 \n",
            "Epoch 280/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8065 - loss: 0.6058 \n",
            "Epoch 281/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8238 - loss: 0.5169 \n",
            "Epoch 282/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8474 - loss: 0.4985 \n",
            "Epoch 283/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8429 - loss: 0.4842 \n",
            "Epoch 284/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8348 - loss: 0.5458\n",
            "Epoch 285/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8268 - loss: 0.5077 \n",
            "Epoch 286/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8064 - loss: 0.5506 \n",
            "Epoch 287/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8074 - loss: 0.5923 \n",
            "Epoch 288/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8116 - loss: 0.5205 \n",
            "Epoch 289/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8394 - loss: 0.5276  \n",
            "Epoch 290/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8308 - loss: 0.5066 \n",
            "Epoch 291/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8363 - loss: 0.5382  \n",
            "Epoch 292/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8429 - loss: 0.6141 \n",
            "Epoch 293/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8375 - loss: 0.5150 \n",
            "Epoch 294/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8523 - loss: 0.4766 \n",
            "Epoch 295/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8435 - loss: 0.5135  \n",
            "Epoch 296/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8438 - loss: 0.4763 \n",
            "Epoch 297/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8291 - loss: 0.5046 \n",
            "Epoch 298/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8748 - loss: 0.4072 \n",
            "Epoch 299/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8381 - loss: 0.4509 \n",
            "Epoch 300/300\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8937 - loss: 0.4124 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bxlZNSQQTwpg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from sklearn.model_selection import train_test_split\n",
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "\n",
        "with open('intents.json') as f:\n",
        "    data = json.load(f)\n",
        "\n",
        "texts = []\n",
        "labels = []\n",
        "label_map = {}\n",
        "for idx, intent in enumerate(data['intents']):\n",
        "    label_map[intent['tag']] = idx\n",
        "    for pattern in intent['patterns']:\n",
        "        texts.append(pattern)\n",
        "        labels.append(idx)\n",
        "\n",
        "train_texts, val_texts, train_labels, val_labels = train_test_split(texts, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "train_encodings = tokenizer(train_texts, truncation=True, padding='max_length',\n",
        "                            max_length=128, return_tensors=\"pt\")\n",
        "val_encodings = tokenizer(val_texts, truncation=True, padding='max_length',\n",
        "                          max_length=128, return_tensors=\"pt\")\n",
        "\n",
        "train_labels = torch.tensor(train_labels)\n",
        "val_labels = torch.tensor(val_labels)\n"
      ],
      "metadata": {
        "id": "FvPIrnF7TwsW"
      },
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TextDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: val[idx] for key, val in self.encodings.items()}\n",
        "        item['labels'] = self.labels[idx]\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.encodings.input_ids)\n",
        "\n",
        "train_dataset = TextDataset(train_encodings, train_labels)\n",
        "val_dataset = TextDataset(val_encodings, val_labels)\n"
      ],
      "metadata": {
        "id": "Vmth28o3JJOh"
      },
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import Trainer, TrainingArguments\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',\n",
        "    num_train_epochs=5,\n",
        "    per_device_train_batch_size=4,\n",
        "    per_device_eval_batch_size=4,\n",
        "    warmup_steps=500,\n",
        "    weight_decay=0.01,\n",
        "    logging_dir='./logs',\n",
        "    logging_steps=10,\n",
        "    eval_strategy=\"steps\",\n",
        "    save_steps=500,\n",
        "    save_total_limit=2,\n",
        "    load_best_model_at_end=True,\n",
        "    learning_rate=5e-5,\n",
        "    fp16=True,\n",
        "    label_smoothing_factor=0.1)\n",
        "\n"
      ],
      "metadata": {
        "id": "O5z-geHVTwvW"
      },
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=len(label_map))\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,)\n",
        "\n",
        "trainer.train()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ocamOIqsJQMd",
        "outputId": "2dd5574d-2bbb-4e37-e391-cb405de87ab6"
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='405' max='405' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [405/405 1:10:04, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>3.576600</td>\n",
              "      <td>3.645814</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>3.620700</td>\n",
              "      <td>3.643646</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>3.639100</td>\n",
              "      <td>3.636702</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>3.696400</td>\n",
              "      <td>3.631667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>3.679400</td>\n",
              "      <td>3.620124</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>60</td>\n",
              "      <td>3.663200</td>\n",
              "      <td>3.609043</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>70</td>\n",
              "      <td>3.665900</td>\n",
              "      <td>3.597828</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>80</td>\n",
              "      <td>3.688100</td>\n",
              "      <td>3.591213</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>90</td>\n",
              "      <td>3.613900</td>\n",
              "      <td>3.601631</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>3.636400</td>\n",
              "      <td>3.566852</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>110</td>\n",
              "      <td>3.616700</td>\n",
              "      <td>3.532210</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>120</td>\n",
              "      <td>3.562300</td>\n",
              "      <td>3.518632</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>130</td>\n",
              "      <td>3.502200</td>\n",
              "      <td>3.500570</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>140</td>\n",
              "      <td>3.469400</td>\n",
              "      <td>3.488501</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>3.431900</td>\n",
              "      <td>3.454175</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>160</td>\n",
              "      <td>3.531200</td>\n",
              "      <td>3.431758</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>170</td>\n",
              "      <td>3.333000</td>\n",
              "      <td>3.420616</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>180</td>\n",
              "      <td>3.357300</td>\n",
              "      <td>3.401774</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>190</td>\n",
              "      <td>3.316000</td>\n",
              "      <td>3.324189</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>3.331800</td>\n",
              "      <td>3.299636</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>210</td>\n",
              "      <td>3.217200</td>\n",
              "      <td>3.281833</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>220</td>\n",
              "      <td>3.257800</td>\n",
              "      <td>3.231609</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>230</td>\n",
              "      <td>3.182300</td>\n",
              "      <td>3.202103</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>240</td>\n",
              "      <td>3.144000</td>\n",
              "      <td>3.125470</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>250</td>\n",
              "      <td>2.969400</td>\n",
              "      <td>3.049071</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>260</td>\n",
              "      <td>2.944900</td>\n",
              "      <td>2.966759</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>270</td>\n",
              "      <td>2.698800</td>\n",
              "      <td>2.935606</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>280</td>\n",
              "      <td>2.973500</td>\n",
              "      <td>2.887466</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>290</td>\n",
              "      <td>2.730300</td>\n",
              "      <td>2.820989</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>2.655900</td>\n",
              "      <td>2.738086</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>310</td>\n",
              "      <td>2.354600</td>\n",
              "      <td>2.653741</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>320</td>\n",
              "      <td>2.467500</td>\n",
              "      <td>2.577656</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>330</td>\n",
              "      <td>2.568600</td>\n",
              "      <td>2.508907</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>340</td>\n",
              "      <td>2.042000</td>\n",
              "      <td>2.385972</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>350</td>\n",
              "      <td>2.186000</td>\n",
              "      <td>2.331430</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>360</td>\n",
              "      <td>2.106700</td>\n",
              "      <td>2.271568</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>370</td>\n",
              "      <td>1.934200</td>\n",
              "      <td>2.165518</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>380</td>\n",
              "      <td>1.930100</td>\n",
              "      <td>2.107954</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>390</td>\n",
              "      <td>1.962100</td>\n",
              "      <td>2.099976</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>1.846700</td>\n",
              "      <td>1.987153</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=405, training_loss=3.039959356519911, metrics={'train_runtime': 4209.1899, 'train_samples_per_second': 0.385, 'train_steps_per_second': 0.096, 'total_flos': 106594420746240.0, 'train_loss': 3.039959356519911, 'epoch': 5.0})"
            ]
          },
          "metadata": {},
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eval_result = trainer.evaluate()\n",
        "print(f\"Evaluation results: {eval_result}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "CU-FYbrBTw0i",
        "outputId": "5f194a82-4094-4df7-f6d2-df0122560cc2"
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='21' max='21' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [21/21 00:42]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation results: {'eval_loss': 1.943200945854187, 'eval_runtime': 45.6651, 'eval_samples_per_second': 1.774, 'eval_steps_per_second': 0.46, 'epoch': 5.0}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "d0YdQijyN-3_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def chat():\n",
        "    print(\"Start talking with the bot (type quit to stop)!\")\n",
        "    while True:\n",
        "        inp = input(\"You: \")\n",
        "        if inp.lower() == \"quit\":\n",
        "            break\n",
        "\n",
        "        processed_input = preprocess_text(inp)\n",
        "        seq = tokenizer.texts_to_sequences([' '.join(processed_input)])\n",
        "        padded_seq = pad_sequences(seq, maxlen=max_len, truncating='post')\n",
        "\n",
        "        prediction = model.predict(padded_seq)\n",
        "        tag = label_encoder.inverse_transform([np.argmax(prediction)])\n",
        "\n",
        "        for i in data['intents']:\n",
        "            if i['tag'] == tag:\n",
        "                print(f\"Chatbot: {np.random.choice(i['responses'])}\")\n",
        ""
      ],
      "metadata": {
        "id": "hxHPhRn0N_B2"
      },
      "execution_count": 127,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chat()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RfEnbY1-keLW",
        "outputId": "6f112d35-3505-4601-f4e7-8c207d1ae122"
      },
      "execution_count": 130,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Start talking with the bot (type quit to stop)!\n",
            "You: hi\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "Chatbot: Hi there, how can I help?\n",
            "You: what is the timing of school?\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "Chatbot: College is open 8am-5pm Monday-Saturday!\n",
            "You: what is in canteen?\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "Chatbot: Our university has canteen with variety of food available\n",
            "You: what are the food options?\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "Chatbot: Our university has canteen with variety of food available\n",
            "You: damn\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "Chatbot: Hello!\n",
            "You: nice\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "Chatbot: I am glad I helped you\n",
            "You: how are you?\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "Chatbot: Hi there, how can I help?\n",
            "You: how many program offered?\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "Chatbot: Our university offers Information Technology, computer Engineering, Mechanical engineering,Chemical engineering, Civil engineering and extc Engineering.\n",
            "You: quit\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "def preprocess_text(text):\n",
        "    text = text.lower()\n",
        "    return text.split()\n",
        "\n",
        "def chat_response(inp):\n",
        "    processed_input = preprocess_text(inp)\n",
        "    seq = tokenizer.texts_to_sequences([' '.join(processed_input)])\n",
        "    padded_seq = pad_sequences(seq, maxlen=max_len, truncating='post')\n",
        "\n",
        "    prediction = model.predict(padded_seq)\n",
        "    tag = label_encoder.inverse_transform([np.argmax(prediction)])[0]\n",
        "\n",
        "    for i in data['intents']:\n",
        "        if i['tag'] == tag:\n",
        "            return np.random.choice(i['responses'])\n",
        "\n",
        "iface = gr.Interface(\n",
        "    fn=chat_response,\n",
        "    inputs=\"text\",\n",
        "    outputs=\"text\",\n",
        "    title=\"Chatbot\",\n",
        "    description=\"Start chatting with the bot. Type your message and press enter.\")\n",
        "\n",
        "iface.launch()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 645
        },
        "id": "tJVbLgrhTw8R",
        "outputId": "d11c0419-33c3-4483-88d9-a554c899174e"
      },
      "execution_count": 146,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting queue=True in a Colab notebook requires sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Running on public URL: https://c30b8fc0c03e144693.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://c30b8fc0c03e144693.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 146
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Zeh3vWb3JfLj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Yd6SrYDXtJ6a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CiUWzibCTxGy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}